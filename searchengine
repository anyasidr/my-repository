import shelve
import os
import indexator
from moytokenizer import Tokenizer


class SearchEngine(object):
    
    def __init__(self, dbname):
        self.database = shelve.open(dbname, writeback=True)

    def search_one(self, query):
        if not isinstance(query, str):
            raise TypeError
        return self.database.get(query, {})

    def search_many(self, query):
        if not isinstance(query, str):
            raise TypeError
        if query == '':
            return {}
        tokenize = Tokenizer()
        words = list(tokenize.for_index_tokenize(query))
        found = []
        for word in words:
            found.append(self.database[word.text])        
        files = set(found[0])
        for result in found:
            files &= set(result)
        positions = {}
        for file in files:
            for result in found:
                  positions.setdefault(file, []).extend(result[file])
        return positions

    def close(self):
        self.database.close()
    
        

