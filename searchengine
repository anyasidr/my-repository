import shelve
import os
import indexator
from moytokenizer import Tokenizer


class SearchEngine(object):
    
    def __init__(self, dbname):
        self.database = shelve.open(dbname, writeback=True)

    def search_one(self, query):
        if not isinstance(query, str):
            raise TypeError
        return self.database.get(query, {})

    def search_many(self, query):
        if not isinstance(query, str):
            raise TypeError
        if query == '':
            return {}
        tokenize = Tokenizer()
        words = list(tokenize.for_index_tokenize(query))
        found = []
        for word in words:
            found.append(self.database[word.text])        
        files = set(found[0])
        for result in found:
            files &= set(result)
        positions = {}
        for file in files:
            for result in found:
                  positions.setdefault(file, []).extend(result[file])
        return positions

    def close(self):
        self.database.close()


def main():    
    indexer = indexator.Indexator('db')    
    f = open('test1.txt', 'w')
    f.write('То, на что вы смотрите - это тест поисковой системы')
    f.close()
    d = open('test2.txt', 'w')
    d.write('Ну да, это тест программы')
    d.close()
    indexer.indextie_with_lines('test1.txt')
    indexer.indextie_with_lines('test2.txt')
    del indexer
    engine = SearchEngine('db')
    result = engine.search_many('это тест')
    print(result)
    del engine
    if 'test2.txt' in os.listdir(os.getcwd()):
        os.remove('test2.txt')
    if 'test1.txt' in os.listdir(os.getcwd()):
        os.remove('test1.txt')
    for filename in os.listdir(os.getcwd()):            
        if filename == 'db' or filename.startswith('db.'):
            os.remove(filename) 
    
        
if __name__=='__main__':
    main()
